# Mercury ü™ê

Welcome to Mercury: An Efficiency Benchmark for LLM Code Synthesis

Mercury is the first benchmark designed for assessing the code efficiency of Large Language Models (LLMs) in code synthesis tasks. 

It consists of 1,889 programming tasks covering diverse difficulty levels, along with test case generators that produce unlimited cases for comprehensive evaluation. 

You can find our paper at: https://arxiv.org/abs/2402.07844

The dataset is available at: https://huggingface.co/datasets/Elfsong/Mercury
