{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import src.sandbox as sandbox\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "ds = load_dataset(\"Elfsong/Caduceus_v7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1(index):\n",
    "    instance = eval_list[index]\n",
    "    sb = sandbox.Sandbox()\n",
    "    results = list()\n",
    "    \n",
    "    for index, solution in enumerate(instance['solutions']):        \n",
    "        sample = {\n",
    "            \"solution\": solution['solution'],\n",
    "            \"convert_offline\": instance['convert_offline'],\n",
    "            \"evaluate_offline\": instance['evaluate_offline'],\n",
    "            \"entry_point\": instance['entry_point'],\n",
    "            \"test_cases\": json.loads(instance['test_cases']),\n",
    "            \"solution_index\": index,\n",
    "            \"timeout\": 30\n",
    "        }\n",
    "    \n",
    "        results += [sb.run_sample(sample)]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "failed_sample = defaultdict(list)\n",
    "\n",
    "for s_index in tqdm(range(256)):\n",
    "    results = test_1(s_index)\n",
    "    for index, result in enumerate(results):\n",
    "        if result['result'] != 'passed':\n",
    "            print(s_index, result)\n",
    "            failed_sample[s_index] += [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in ds['eval']:\n",
    "    l = len(instance['solutions'])\n",
    "    counter[l] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list, c_list = list(), list()\n",
    "t_list = list()\n",
    "\n",
    "for c in counter:\n",
    "    n_list += [c]\n",
    "    c_list += [counter[c]]\n",
    "    t_list += [c] * counter[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'count': c_list, 'num_of_solution': n_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for instance in ds['eval']:\n",
    "    difficulty = instance['difficulty']\n",
    "    counter[difficulty] += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = sns.barplot(data=df, x='num_of_solution', y='count')\n",
    "plt.set(xlabel=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_list(train_list)\n",
    "eval_ds = Dataset.from_list(eval_list)\n",
    "final_ds = DatasetDict({\"train\":train_ds, \"eval\":eval_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds.push_to_hub('Elfsong/Caduceus_v7', private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mean(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.median(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mode(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('        if not matrix: return []\\n        R, C = len(matrix), len(matrix[0])\\n        visited = [[False] * C for _ in matrix]\\n        dr = [0, 1, 0, -1]\\n        dc = [1, 0, -1, 0]\\n        ans = []\\n        r = c = di = 0\\n        for _ in range(R * C):\\n            ans.append(matrix[r][c])\\n            visited[r][c] = True\\n            cr, cc = r + dr[di], c + dc[di]\\n            if 0 <= cr < R and 0 <= cc < C and not visited[cr][cc]:\\n                r, c = cr, cc\\n            else:\\n                di = (di + 1) % 4\\n                r, c = r + dr[di], c + dc[di]\\n        return ans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample \n",
    "  \n",
    "# Prints list of random items of given length \n",
    "list1 = [1, 2]  \n",
    "  \n",
    "print(sample(list1,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2,3,4,5,6,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./data/mbpp/sanitized-mbpp.json', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for d in data:\n",
    "    task_id = d['task_id']\n",
    "    if task_id >= 11 and task_id <= 510:\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions():\n",
    "    url = \"https://leetcode.com/api/problems/algorithms/\"\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'authority': 'leetcode.cn',\n",
    "        'accept': '*/*',\n",
    "        'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8,zh-CN;q=0.7,zh-HK;q=0.6,zh-TW;q=0.5,zh;q=0.4',\n",
    "        'content-type': 'application/json',\n",
    "        'cookie': '_gid=GA1.2.1098388302.1701430581; gr_user_id=7410146c-e5bc-4739-a7c8-40cb0e580219; a2873925c34ecbd2_gr_session_id=5c028fe5-e819-4177-bc61-685d662a8ea3; a2873925c34ecbd2_gr_session_id_sent_vst=5c028fe5-e819-4177-bc61-685d662a8ea3; Hm_lvt_f0faad39bcf8471e3ab3ef70125152c3=1701430581; _bl_uid=Rtlq0pdemvUjdwuU0mna4wefs90p; csrftoken=AZRVgBFAYbZ8j6ud6Er7hfSUYBoaMMiZyImW25xy9HYJ7Kluvhok6RKzjAofXb3H; LEETCODE_SESSION=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJfYXV0aF91c2VyX2lkIjoiMTgwMDQyMyIsIl9hdXRoX3VzZXJfYmFja2VuZCI6ImRqYW5nby5jb250cmliLmF1dGguYmFja2VuZHMuTW9kZWxCYWNrZW5kIiwiX2F1dGhfdXNlcl9oYXNoIjoiYjg1YTc3ZmYxMDgxNTAwMzg3NzY1YzE3ZGQ0M2I5YTEyYTNhOWYxNWI4YmRhNDVjNjc1ZjFiYmExNGU1YzFmNyIsImlkIjoxODAwNDIzLCJlbWFpbCI6ImR1bWluZ3poZUAxMjYuY29tIiwidXNlcm5hbWUiOiJlbGZzb25nLXYiLCJ1c2VyX3NsdWciOiJlbGZzb25nLXYiLCJhdmF0YXIiOiJodHRwczovL2Fzc2V0cy5sZWV0Y29kZS5jbi9hbGl5dW4tbGMtdXBsb2FkL3VzZXJzL2VsZnNvbmctdi9hdmF0YXJfMTYwMDU0MTMyNy5wbmciLCJwaG9uZV92ZXJpZmllZCI6dHJ1ZSwiX3RpbWVzdGFtcCI6MTcwMTQzMDYzNy4yMjI4ODYsImV4cGlyZWRfdGltZV8iOjE3MDM5NjI4MDAsInZlcnNpb25fa2V5XyI6Mn0.xj1NZG6DUHjo12TmwApzDnzbTIS33WSfKWBAy_UkCJg; a2873925c34ecbd2_gr_last_sent_sid_with_cs1=5c028fe5-e819-4177-bc61-685d662a8ea3; a2873925c34ecbd2_gr_last_sent_cs1=elfsong-v; _ga=GA1.1.695723023.1701430580; Hm_lpvt_f0faad39bcf8471e3ab3ef70125152c3=1701430639; a2873925c34ecbd2_gr_cs1=elfsong-v; _ga_PDVPZYN3CW=GS1.1.1701430580.1.1.1701431322.52.0.0; LEETCODE_SESSION=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.e30.KpufdHIo8CeGduwC5DCQoba8bmWCjJ9mUTYQ4npFdlk; csrftoken=AZRVgBFAYbZ8j6ud6Er7hfSUYBoaMMiZyImW25xy9HYJ7Kluvhok6RKzjAofXb3H',\n",
    "        'referer': 'https://leetcode.cn/problems/two-sum/submissions/486127358/',\n",
    "        'sec-ch-ua': '\"Google Chrome\";v=\"119\", \"Chromium\";v=\"119\", \"Not?A_Brand\";v=\"24\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"macOS\"',\n",
    "        'sec-fetch-dest': 'empty',\n",
    "        'sec-fetch-mode': 'cors',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n",
    "        'x-csrftoken': 'AZRVgBFAYbZ8j6ud6Er7hfSUYBoaMMiZyImW25xy9HYJ7Kluvhok6RKzjAofXb3H'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    questions = response.json()\n",
    "    question_dict= dict()\n",
    "\n",
    "    for question in questions[\"stat_status_pairs\"]:\n",
    "        # if not question[\"paid_only\"]:\n",
    "        slug_name = question[\"stat\"][\"question__title_slug\"]\n",
    "        paid_only = question[\"paid_only\"]\n",
    "        question_dict[slug_name] = paid_only\n",
    "        \n",
    "    return question_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = ds['train'].to_list()\n",
    "eval_list = ds['eval'].to_list()\n",
    "all_questions = get_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_index = list()\n",
    "for index, instance in enumerate(train_list):\n",
    "    slug_name = instance['slug_name']\n",
    "    if all_questions[slug_name]:\n",
    "        paid_index += [index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in paid_index[::-1]:\n",
    "    del train_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_index = list()\n",
    "for index, instance in enumerate(eval_list):\n",
    "    slug_name = instance['slug_name']\n",
    "    if all_questions[slug_name]:\n",
    "        paid_index += [index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in paid_index[::-1]:\n",
    "    del eval_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_list(train_list)\n",
    "eval_ds = Dataset.from_list(eval_list)\n",
    "final_ds = DatasetDict({\"train\":train_ds, \"eval\":eval_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds.push_to_hub('Elfsong/Caduceus_v8', private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Elfsong/Caduceus_v8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1633 + 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Difficulty': ['Easy', 'Medium', 'Hard'],\n",
    "    'Train': [446, 968, 219],\n",
    "    'Eval': [88, 81, 87]\n",
    "})\n",
    "\n",
    "# Create a pie chart for Train\n",
    "plt.pie(df['Train'], labels=df['Difficulty'], autopct='%1.1f%%', startangle=90, pctdistance=0.85, radius=1)\n",
    "\n",
    "# Create a pie chart for Eval inside the previous one\n",
    "plt.pie(df['Eval'], labels=df['Difficulty'], autopct='%1.1f%%', startangle=90, pctdistance=0.85, radius=0.75)\n",
    "\n",
    "# Draw a white circle at the center\n",
    "centre_circle = plt.Circle((0, 0), 0.50, fc='white')\n",
    "fig = plt.gcf()\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "fig.gca().add_artist(centre_circle)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Elfsong/Caduceus_v8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_name_dict = dict()\n",
    "for instance in ds['eval']:\n",
    "    slug_name = instance['slug_name']\n",
    "    difficulty = instance['difficulty']\n",
    "    slug_name_dict[slug_name] = difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/deepseek-ai/deepseek-coder-6.7b-instruct_eval.json') as data_f:\n",
    "    data = json.load(data_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.98830896604889\n",
      "63.553644910261475\n",
      "58.801186904466384\n",
      "45.717128780962405\n"
     ]
    }
   ],
   "source": [
    "total_a, sum_a = 0, 0\n",
    "total_e, sum_e = 0, 0\n",
    "total_m, sum_m = 0, 0\n",
    "total_h, sum_h = 0, 0\n",
    "\n",
    "for slug_name in data:\n",
    "    results = data[slug_name]\n",
    "    beyonds = [result['beyond_p'] for result in results]\n",
    "    beyond = max(beyonds[:1])\n",
    "    \n",
    "    total_a += 1\n",
    "    sum_a += beyond\n",
    "    \n",
    "    if slug_name_dict[slug_name] == 'Easy':\n",
    "        total_e += 1\n",
    "        sum_e += beyond\n",
    "    elif slug_name_dict[slug_name] == 'Medium':\n",
    "        total_m += 1\n",
    "        sum_m += beyond\n",
    "    elif slug_name_dict[slug_name] == 'Hard':\n",
    "        total_h += 1\n",
    "        sum_h += beyond\n",
    "        \n",
    "    \n",
    "final_beyond_a = sum_a / total_a * 100\n",
    "print(final_beyond_a)\n",
    "\n",
    "final_beyond_e = sum_e / total_e * 100\n",
    "print(final_beyond_e)\n",
    "\n",
    "final_beyond_m = sum_m / total_m * 100\n",
    "print(final_beyond_m)\n",
    "\n",
    "final_beyond_h = sum_h / total_h * 100\n",
    "print(final_beyond_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy\n",
      "defaultdict(<class 'int'>, {'passed': 53, 'failed@cases': 31, 'failed@load': 1, 'failed@eval': 3})\n",
      "Medium\n",
      "defaultdict(<class 'int'>, {'failed@cases': 31, 'passed': 39, 'failed@eval': 9, 'failed@load': 2})\n",
      "Hard\n",
      "defaultdict(<class 'int'>, {'failed@cases': 59, 'passed': 9, 'failed@eval': 16, 'failed@load': 3})\n"
     ]
    }
   ],
   "source": [
    "with open('./data/codellama/CodeLlama-7b-Instruct-hf_eval_new.json') as data_f:\n",
    "    data = json.load(data_f)\n",
    "    \n",
    "\n",
    "for d in ['Easy', 'Medium', 'Hard']:\n",
    "    status = defaultdict(int)\n",
    "    for slug_name in data:\n",
    "        if slug_name_dict[slug_name] == d:\n",
    "            result = data[slug_name][0]['result']['result']\n",
    "            status[result] += 1\n",
    "    print(d)\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "53 + 39 + 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
